{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/thanuja/Dropbox/coursera/Milestone1/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyspark intitialization\n",
    "\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import chain\n",
    "import warnings\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('org queries') \\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .getOrCreate() \n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019 payments file\n",
    "general_payments_df = spark.read.option(\"header\",True)\\\n",
    "    .csv(BASE_DIR + 'OP_DTL_GNRL_PGYR2019_P06302021.csv')\n",
    "\n",
    "general_payments_df.agg(\n",
    "    F.sum('Total_Amount_of_Payment_USDollars').alias('sum_payments'),\n",
    "    F.count('*').alias('num_payments')\n",
    ").show()\n",
    "\n",
    "general_payments_df.select(F.countDistinct('Physician_Profile_ID')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_payments_df = general_payments_df.where(\n",
    "    F.col('Covered_Recipient_Type') == 'Covered Recipient Physician')\\\n",
    "    .select(F.col('Physician_Profile_ID'),\n",
    "           F.col('Physician_First_Name'),\n",
    "           F.col('Physician_Middle_Name'),\n",
    "           F.col('Physician_Last_Name'),\n",
    "           F.col('Recipient_Primary_Business_Street_Address_Line1'),\n",
    "           F.col('Recipient_State'),\n",
    "           F.col('Recipient_City'),\n",
    "           F.col('Recipient_Zip_Code'),\n",
    "           F.col('Total_Amount_of_Payment_USDollars'))\n",
    "\n",
    "# changing payment column to double\n",
    "hcp_payments_df = hcp_payments_df.withColumn(\"Total_Amount_of_Payment_USDollars\",\n",
    "                                             hcp_payments_df[\"Total_Amount_of_Payment_USDollars\"].cast('double'))\\\n",
    "                                 .withColumn('zip', F.substring('Recipient_Zip_Code', 1, 5))\n",
    "\n",
    "physician_fields = ['Physician_Profile_ID','Physician_First_Name', 'Physician_Middle_Name',\n",
    "                                           'Physician_Last_Name', 'Recipient_Primary_Business_Street_Address_Line1',\n",
    "                                           'Recipient_State', 'Recipient_City', 'zip']\n",
    "\n",
    "physician_payments_df = hcp_payments_df.groupBy(physician_fields).agg(\n",
    "    F.sum('Total_Amount_of_Payment_USDollars').alias('sum_payments')\n",
    ")\n",
    "\n",
    "# get average per zip to compare each physician to others in their area\n",
    "median_percentile = F.expr('percentile_approx(sum_payments, 0.5)')\n",
    "zip_payments_df = physician_payments_df.groupBy('zip').agg(\n",
    "    median_percentile.alias('median_payment')\n",
    ")\n",
    "\n",
    "physician_payments_df = physician_payments_df.join(on='zip', other=zip_payments_df)\n",
    "\n",
    "\n",
    "def normalize(raw, median):\n",
    "    if median is None or raw is None:\n",
    "        return raw\n",
    "    #if std is None or avg is None or std == 0:\n",
    "    #    return raw\n",
    "    #return (raw - avg) / std\n",
    "    return raw / median\n",
    "\n",
    "normalize_udf = F.udf(normalize, FloatType())\n",
    "\n",
    "physician_payments_df = physician_payments_df.withColumn('normalized_payment',\n",
    "                     normalize_udf('sum_payments',\n",
    "                                   'median_payment'))\n",
    "#hcp_payments_df.select('avg_payment', 'normalized_payment', 'Total_Amount_of_Payment_USDollars').show()\n",
    "\n",
    "print(physician_payments_df.columns)\n",
    "'''\n",
    "#sum payment column for each healthcare provider\n",
    "hcp_payments_df = hcp_payments_df.groupBy(['Physician_Profile_ID','Physician_First_Name', 'Physician_Middle_Name',\n",
    "                                           'Physician_Last_Name', 'Recipient_Primary_Business_Street_Address_Line1',\n",
    "                                           'Recipient_State', 'Recipient_City', 'zip'])\\\n",
    "                                    .agg(F.sum('normalized_payment').alias(\"sum_payment\"),F.sum('Total_Amount_of_Payment_USDollars').alias(\"total_sum\"))\n",
    "print(hcp_payments_df.columns)\n",
    "'''\n",
    "\n",
    "#mapping file\n",
    "ppi_npi_matches_df_schema = StructType([\n",
    "    StructField(\"FirstName\", StringType(), True),\n",
    "    StructField(\"LastName\", StringType(), True),\n",
    "    StructField(\"NPI\", StringType(), True),\n",
    "    StructField(\"Physician_Profile_ID\", StringType(), True),\n",
    "    StructField(\"Score\", FloatType(), True),\n",
    "    StructField(\"NatAddr\", StringType(), True),\n",
    "    StructField(\"AddrScore\", FloatType(), True),\n",
    "    StructField(\"SupplAddr\", StringType(), True),\n",
    "    StructField(\"NatStateCity\", StringType(), True),\n",
    "    StructField(\"StateCityScore\", FloatType(), True),\n",
    "    StructField(\"SupplStateCity\", StringType(), True),\n",
    "    StructField(\"NatTaxonomy\", StringType(), True),\n",
    "    StructField(\"TaxonomyScore\", FloatType(), True),\n",
    "    StructField(\"SupplTaxonomy\", StringType(), True),\n",
    "    StructField(\"NatMiddleName\", StringType(), True),\n",
    "    StructField(\"MiddleNameScore\", FloatType(), True),\n",
    "    StructField(\"SupplMiddleName\", StringType(), True)])\n",
    "\n",
    "\n",
    "ppi_npi_matches_df = spark.read\\\n",
    "    .csv(BASE_DIR + 'data_processing/filtered_out/filtered_hcp_matches.csv',header=False, schema=ppi_npi_matches_df_schema)\n",
    "#ppi_npi_matches_df = ppi_npi_matches_df[['NPI', 'Physician_Profile_ID']]\n",
    "\n",
    "# TODO: adjust payments by cost of living and/or state/zip code average\n",
    "\n",
    "# join payments file with mapping file to filter out physicians that don't have payment information\n",
    "physician_payments_df = physician_payments_df.join(on='Physician_Profile_ID', other=ppi_npi_matches_df)\n",
    "physician_payments_df.select('sum_payments', 'normalized_payment', 'median_payment').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting only physician profile id and total payment information from the merged file\n",
    "\n",
    "hcp_total_payments_df = physician_payments_df.select(F.col('NPI'),F.col('sum_payments'))\n",
    "hcp_total_payments_df = physician_payments_df.dropna()\n",
    "hcp_total_payments_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance ratings file\n",
    "cms_ec_ratings_df = spark.read.options(header='True').csv(BASE_DIR + 'ec_score_file.csv')\n",
    "\n",
    "cms_ec_ratings_df = cms_ec_ratings_df.withColumnRenamed(' final_MIPS_score', 'final_MIPS_score')\n",
    "cms_ec_ratings_df = cms_ec_ratings_df[['NPI', 'final_MIPS_score']]\n",
    "\n",
    "float_cols = ['final_MIPS_score']\n",
    "\n",
    "#drop rows if all values in score cols have null values\n",
    "cms_ec_ratings_df = cms_ec_ratings_df.dropna(how='all',subset=float_cols)\n",
    "\n",
    "#cast float_cols to float\n",
    "#for col_name in float_cols:\n",
    "#    cms_org_ratings_df = cms_org_ratings_df.withColumn(col_name, F.col(col_name).cast('float'))\n",
    "cms_ec_ratings_df.show()\n",
    "print(cms_ec_ratings_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_ec_ratings_pa_df = cms_ec_ratings_df.join(on='NPI', other=physician_payments_df)\n",
    "hcp_ec_ratings_pa_df.show(truncate=False)\n",
    "hcp_ec_ratings_pa_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join org_payments and org_ratings to merge payments data and perf ratings data at organization level\n",
    "hcp_ec_ratings_payments_df = cms_ec_ratings_df.join(on='NPI', other=hcp_total_payments_df)\n",
    "hcp_ec_ratings_payments_df.show(truncate=False)\n",
    "hcp_ec_ratings_payments_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_ec_ratings_pa_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_ec_ratings_payments_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't consider payments below this threshold, as they are too small to have much influence on physician behavior\n",
    "payment_threshold = 10\n",
    "\n",
    "#covert pyspark df to pandas df to use for our visualizations\n",
    "hcp_ec_ratings_payments_pddf = hcp_ec_ratings_payments_df.toPandas()\n",
    "hcp_ec_ratings_payments_pddf['final_MIPS_score'] = hcp_ec_ratings_payments_pddf['final_MIPS_score'].astype(float)\n",
    "#hcp_ec_ratings_payments_pddf['log_payment'] = np.log(hcp_ec_ratings_payments_pddf['sum_payment'])\n",
    "hcp_ec_ratings_payments_pddf = hcp_ec_ratings_payments_pddf[hcp_ec_ratings_payments_pddf['final_MIPS_score'] > 30.0]\n",
    "hcp_ec_ratings_payments_pddf = hcp_ec_ratings_payments_pddf[hcp_ec_ratings_payments_pddf['sum_payments'] > payment_threshold]\n",
    "#print(hcp_ec_ratings_payments_pddf)\n",
    "#disable the altair error when dataset rows is > 5000\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "def zscale(column):\n",
    "    return (column - column.mean()) / column.std()\n",
    "\n",
    "lg_payments = zscale(np.log10(hcp_ec_ratings_payments_pddf['sum_payments']))\n",
    "#lg_payments = hcp_ec_ratings_payments_pddf['sum_payments']\n",
    "mips_score = zscale(hcp_ec_ratings_payments_pddf['final_MIPS_score'])\n",
    "print('correlation', lg_payments.corr(mips_score))\n",
    "\n",
    "#payments are in logarithmic scale to account for outliers\n",
    "cms_payments_ratings_chart = alt.Chart(\n",
    "    hcp_ec_ratings_payments_pddf[hcp_ec_ratings_payments_pddf['sum_payments'] < 1000000].sample(5000),\n",
    "    title='Physician Performance Rating by Total Payments'\n",
    ").mark_point().encode(\n",
    "    x=alt.X('sum_payments:Q', title='Total Payments (USD)',\n",
    "            scale=alt.Scale(type='log', domain=[payment_threshold, 1000000])),\n",
    "    #x=alt.X('normalized_payment:Q'),\n",
    "    y=alt.Y('final_MIPS_score:Q', title='Overall Performance Rating',\n",
    "            scale=alt.Scale(type='linear', domain=[30, 100]))\n",
    ").properties(width=700, height=200)\n",
    "cms_payments_ratings_chart\n",
    "#(payments_ratings_chart).properties(width=800,height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(hcp_ec_ratings_pa_df.columns)\n",
    "hcp_ec_ratings_pa_ab0 = hcp_ec_ratings_pa_df.toPandas()\n",
    "#print(hcp_ec_ratings_pa_ab0.dtypes)\n",
    "hcp_ec_ratings_pa_ab0 = hcp_ec_ratings_pa_ab0[hcp_ec_ratings_pa_ab0.sum_payments>0]\n",
    "hcp_ec_ratings_pa_ab0=hcp_ec_ratings_pa_ab0.sort_values(by='sum_payments', ascending=False)\n",
    "hcp_ec_ratings_pa_ab0=hcp_ec_ratings_pa_ab0.head(50)\n",
    "print(hcp_ec_ratings_pa_ab0.head(10))\n",
    "scale = alt.Scale(\n",
    "    domain=[30,100],\n",
    "    range=['pink', 'green'],\n",
    "    type='linear'\n",
    ")\n",
    "\n",
    "alt.Chart(hcp_ec_ratings_pa_ab0).mark_bar().encode(\n",
    "    x=alt.X('sum_payments:Q', title='Sum of payments for 2019 (USD)'),\n",
    "    y=alt.Y(\"Physician_Last_Name:N\", title='Physician Last Name', sort='-x'),\n",
    "    color=alt.Color('final_MIPS_score:Q', title='Final MIPS rating', scale=scale),\n",
    ").properties(height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_payment_corr = hcp_ec_ratings_payments_pddf.corr().reset_index()\n",
    "score_payment_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxonomies provided by CMS\n",
    "hcp_taxonomies =spark.read.options(header='True').csv(BASE_DIR + \"Medicare_Provider_and_Supplier_Taxonomy_Crosswalk_October_2021.csv\")\n",
    "#rename columns and remove whitespaces as appropriate.\n",
    "hcp_taxonomies = hcp_taxonomies.withColumnRenamed(\"PROVIDER TAXONOMY DESCRIPTION:  TYPE, CLASSIFICATION, SPECIALIZATION\",\"detail_desc\")\\\n",
    "                               .withColumnRenamed(\"MEDICARE PROVIDER/SUPPLIER TYPE DESCRIPTION\",\"hl_desc\")\\\n",
    "                               .withColumnRenamed(\"MEDICARE SPECIALTY CODE\",\"sp_code\")\\\n",
    "                               .withColumnRenamed(\"PROVIDER TAXONOMY CODE\",\"tx_code\")\n",
    "hcp_taxonomies = hcp_taxonomies.withColumn('tx_code', F.trim(hcp_taxonomies.tx_code))\n",
    "hcp_taxonomies.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionaries with taxcodes as key and value being high level and detailed descriptions of specialities.\n",
    "tx_codes = hcp_taxonomies.select(F.collect_list('tx_code')).first()[0]\n",
    "detail_descs = hcp_taxonomies.select(F.collect_list('detail_desc')).first()[0]\n",
    "tax_detail_dict = dict(zip(tx_codes, detail_descs))\n",
    "\n",
    "hl_descs = hcp_taxonomies.select(F.collect_list('hl_desc')).first()[0]\n",
    "tax_hl_dict = dict(zip(tx_codes, hl_descs))\n",
    "\n",
    "# this file has mapping of specialities between CMS taxonomy file and DAC_NationalDownloadableFile.csv\n",
    "cms_npi_map = pd.read_csv(BASE_DIR + \"mapping_taxonomies.csv\")\n",
    "\n",
    "# dictionary of the mapping cms speciality and specialities listed in DAC_NationalDownloadableFile.csv\n",
    "cms_nat_dict = dict(zip(cms_npi_map.CMS_SPECIALITY, cms_npi_map.NAT_SPECIALITY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#physcians supplemental file (fname,lname,mname,address,state,city,zip,taxonomy,speciality)\n",
    "hcp_suppl_file_df = spark.read.options(header='True').csv(BASE_DIR + \"OP_PH_PRFL_SPLMTL_P06302021.csv\")\n",
    "\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumnRenamed(\"Physician_Profile_First_Name\",\"f_name\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_Last_Name\",\"l_name\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_Alternate_Middle_Name\",\"ma_name\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_Middle_Name\",\"m_name\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_Address_Line_1\",\"adr_ln_1\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_Address_Line_2\",\"adr_ln_2\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_City\",\"city\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_State\",\"state\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_Zipcode\",\"zip\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_OPS_Taxonomy_1\",\"txcode_1\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_OPS_Taxonomy_2\",\"txcode_2\")\\\n",
    "                                           .withColumnRenamed(\"Physician_Profile_OPS_Taxonomy_3\",\"txcode_3\")\n",
    "\n",
    "\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn('txcode_1', trim(hcp_suppl_file_df.txcode_1))\n",
    "\n",
    "#separate 5 digit zip from 4 Codes\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"zip\", F.regexp_replace(\"zip\", \"-\", \" \"))\n",
    "\n",
    "#add specialities from DAC_NationalDownloadableFile (NAT) to supplemental file for 3 different taxonomy codes.\n",
    "mapping_expr1 = create_map([lit(x) for x in chain(*tax_hl_dict.items())])\n",
    "mapping_expr2 = create_map([lit(x) for x in chain(*tax_detail_dict.items())])\n",
    "mapping_expr3 = create_map([lit(x) for x in chain(*cms_nat_dict.items())])\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"cms_hl_speciality_1\", mapping_expr1.getItem(col(\"txcode_1\")))\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"cms_detail_speciality_1\", mapping_expr2.getItem(col(\"txcode_1\")))\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"nat_speciality_1\", mapping_expr3.getItem(col(\"txcode_1\")))\n",
    "\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"cms_hl_speciality_2\", mapping_expr1.getItem(col(\"txcode_2\")))\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"cms_detail_speciality_2\", mapping_expr2.getItem(col(\"txcode_2\")))\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"nat_speciality_2\", mapping_expr3.getItem(col(\"txcode_2\")))\n",
    "\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"cms_hl_speciality_3\", mapping_expr1.getItem(col(\"txcode_3\")))\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"cms_detail_speciality_3\", mapping_expr2.getItem(col(\"txcode_3\")))\n",
    "hcp_suppl_file_df = hcp_suppl_file_df.withColumn(\"nat_speciality_3\", mapping_expr3.getItem(col(\"txcode_3\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_payments_suppl_df = hcp_ec_ratings_pa_df.join(on='Physician_Profile_ID', other=hcp_suppl_file_df)\n",
    "hcp_payments_suppl_spec_df=hcp_payments_suppl_df.groupby(\"cms_hl_speciality_1\").agg(\n",
    "    sum(\"sum_payments\").alias(\"payments\"),\n",
    "    count(\"Physician_Profile_ID\").alias(\"num_doctors\")\n",
    ").sort(desc(\"payments\"))\n",
    "hcp_payments_suppl_spec_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_payments_suppl_spec_pddf=hcp_payments_suppl_spec_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hcp_payments_suppl_spec_pddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = alt.Scale(\n",
    "    domain=[30,100],\n",
    "    range=['pink', 'green'],\n",
    "    type='linear'\n",
    ")\n",
    "\n",
    "print(hcp_payments_suppl_spec_pddf.dtypes)\n",
    "\n",
    "# TODO: color of average rating \n",
    "# https://altair-viz.github.io/gallery/top_k_items.html\n",
    "alt.Chart(hcp_payments_suppl_spec_pddf).mark_bar().encode(\n",
    "    x=alt.X('payments:Q', title='Total Payments'),\n",
    "    y=alt.Y(\"cms_hl_speciality_1:N\", sort='-x', title=None),\n",
    ").transform_window(\n",
    "    rank='rank(payments)',\n",
    "    sort=[alt.SortField('payments', order='descending')]\n",
    ").transform_filter(\n",
    "    (alt.datum.rank < 10)\n",
    ").properties(height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
