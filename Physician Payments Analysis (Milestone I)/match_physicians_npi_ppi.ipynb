{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR='/home/thanuja/Dropbox/coursera/Milestone1/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from itertools import chain\n",
    "from pyspark.sql import types as t\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyspark.sql.types import StructType,StructField, StringType,IntegerType\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8845595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyspark initialization\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .appName('cms_physicians_analysis') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# reads files,finds match score and outputs the matched,unmatched rows into files.\n",
    "class Row:\n",
    "    def __init__(self, file):\n",
    "        line = file.readline()\n",
    "        self.eof = False\n",
    "        if not line:\n",
    "            raise EOFError('End of input')\n",
    "        data = line.split(',')\n",
    "        self.id = data[0]\n",
    "        self.name = (data[1], data[2])\n",
    "        self.address = data[3].strip()\n",
    "        self.state_city = data[4].strip()\n",
    "        self.taxonomies = data[5].strip()\n",
    "        self.middle_name = data[6].strip()\n",
    "        self.data = [self.address, self.state_city, self.taxonomies, self.middle_name]\n",
    "    \n",
    "    def write(self, file):\n",
    "        file.write(f'{self.id},{self.name[0]},{self.name[1]},{self.address},{self.state_city},{self.taxonomies},{self.middle_name}\\n')\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.id + '|' + self.name[0] + ' ' + self.name[1]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "# Assumes row1.name == row2.name\n",
    "def write_match(file, match):\n",
    "    row1, row2, score, score_breakdown = match\n",
    "    file.write(f'{row1.name[0]},{row1.name[1]},{row1.id},{row2.id},{score},'\n",
    "               f'{row1.address},{score_breakdown[0]},{row2.address},'\n",
    "               f'{row1.state_city},{score_breakdown[1]},{row2.state_city},'\n",
    "               f'{row1.taxonomies},{score_breakdown[2]},{row2.taxonomies},'\n",
    "               f'{row1.middle_name},{score_breakdown[3]},{row2.middle_name}\\n')\n",
    "\n",
    "NUM_FIELDS=4\n",
    "#array[[addresses],[state and citie],[taxonomies],[middle names]]\n",
    "def get_array(rows):\n",
    "    result = []\n",
    "    for field in range(NUM_FIELDS):\n",
    "        column = []\n",
    "        for row in rows:\n",
    "            data = row.data[field].strip(' \"\\'')\n",
    "            column.append(data)\n",
    "        result.append(column)\n",
    "    return result\n",
    "#uses TF-IDF to transform text into vectors and then applies cosine similarity. Finds the best score based on cosine similarity.\n",
    "def match_rows(npi_rows, suppl_rows):\n",
    "    npi_array = get_array(npi_rows)\n",
    "    #print('npi_array', len(npi_array), npi_array)\n",
    "    suppl_array = get_array(suppl_rows)\n",
    "    #print('suppl array', len(suppl_array), suppl_array)\n",
    "\n",
    "    npi_matrixes = []\n",
    "    suppl_matrixes = []\n",
    "    for field in range(NUM_FIELDS):\n",
    "        # Modify pattern to allow single letter tokens, for middle initial and street directions\n",
    "        vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "                                    stop_words=['MEDICINE', 'SUITE', 'STE'])\n",
    "        # Add 'STOP' to prevent vocabulary from being empty, which causes error\n",
    "        npi_field = vectorizer.fit_transform(npi_array[field] + ['STOP'])\n",
    "        suppl_field = vectorizer.transform(suppl_array[field] + ['STOP'])\n",
    "        #print('npi_field shape', npi_field.shape, npi_field.shape)\n",
    "        npi_matrixes.append(npi_field)\n",
    "        suppl_matrixes.append(suppl_field)\n",
    "    #print('npi_matrixes len', len(npi_matrixes))\n",
    "    #print('suppl_matrixes len', len(suppl_matrixes))\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    for i in range(len(suppl_array[0])):\n",
    "        best_j = 0\n",
    "        best_score = -1\n",
    "        best_score_breakdown = []\n",
    "        for j in range(len(npi_array[0])):\n",
    "            score = 0\n",
    "            score_breakdown = np.zeros((NUM_FIELDS))\n",
    "            for field in range(NUM_FIELDS):\n",
    "                score_breakdown[field] = cosine_similarity(suppl_matrixes[field][i], npi_matrixes[field][j])\n",
    "                #print('score', score_breakdown[field], 'suppl', suppl_array[field][i], 'npi', npi_array[field][j])\n",
    "            score = score_breakdown.mean()\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                best_score_breakdown = score_breakdown\n",
    "                best_j = j\n",
    "        #print('best score', best_score, best_score_breakdown)\n",
    "        result.append((npi_rows[best_j], suppl_rows[i], best_score, best_score_breakdown))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc08913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#traverses through the hcp_suppl.csv and hcp_npi.csv and finds the matches and writes it to file.\n",
    "# unmatched rows are written in hcp_npi_unmatched.csv and hcp_suppl_unmatched.csv\n",
    "# ideally bad skips should not occur if the input files are sorted.\n",
    "OUT_DIR = BASE_DIR + 'data_processing/matched_out/'\n",
    "IN_DIR = BASE_DIR + 'data_processing/combined_out/'\n",
    "npi_sorted_file = open(IN_DIR + 'hcp_npi.csv', 'rt')\n",
    "suppl_sorted_file = open(IN_DIR + 'hcp_suppl.csv', 'rt')\n",
    "matches_file = open(OUT_DIR + 'hcp_matches.csv', 'wt')\n",
    "npi_unmatched_file = open(OUT_DIR + 'hcp_npi_unmatched.csv', 'wt')\n",
    "suppl_unmatched_file = open(OUT_DIR + 'hcp_suppl_unmatched.csv', 'wt')\n",
    "\n",
    "npi_unmatched = []\n",
    "suppl_unmatched = []\n",
    "npi_row = Row(npi_sorted_file)\n",
    "suppl_row = Row(suppl_sorted_file)\n",
    "npi_line = 0\n",
    "suppl_line = 0\n",
    "npi_unmatched = 0\n",
    "suppl_unmatched = 0\n",
    "matched = 0\n",
    "\n",
    "def inc_line(name, line_no):\n",
    "    if line_no % 10000 == 0:\n",
    "        print(name, line_no)\n",
    "    return line_no + 1\n",
    "\n",
    "def inc_npi():\n",
    "    global npi_line\n",
    "    npi_line = inc_line('npi %s matched=%d unmatched=%d' % (npi_row.name, matched, npi_unmatched), npi_line)\n",
    "\n",
    "def inc_suppl():\n",
    "    global suppl_line\n",
    "    suppl_line = inc_line('suppl %s matched=%d unmatched=%d' % (suppl_row.name, matched, suppl_unmatched), suppl_line)\n",
    "\n",
    "#limit = 1200000\n",
    "debug = False\n",
    "try:\n",
    "    while True:#npi_line < limit and suppl_line < limit:\n",
    "        if npi_line == 0:\n",
    "            # skip header\n",
    "            print('skipping npi', npi_row.data)\n",
    "            print('skipping suppl', suppl_row.data)\n",
    "            npi_row = Row(npi_sorted_file)\n",
    "            suppl_row = Row(suppl_sorted_file)\n",
    "            inc_npi()\n",
    "            inc_suppl()\n",
    "            continue\n",
    "\n",
    "        npi_skipped = []\n",
    "        suppl_skipped = []\n",
    "        while npi_row.name != suppl_row.name:\n",
    "            while npi_row.name < suppl_row.name:\n",
    "                if debug:\n",
    "                    print('npi', npi_row.name, '<', suppl_row.name)\n",
    "                npi_skipped.append(npi_row.name)\n",
    "                npi_row.write(npi_unmatched_file)\n",
    "                npi_unmatched += 1\n",
    "                npi_row = Row(npi_sorted_file)\n",
    "                inc_npi()\n",
    "            while suppl_row.name < npi_row.name:\n",
    "                if debug:\n",
    "                    print('suppl', suppl_row.name, '<', npi_row.name)\n",
    "                suppl_skipped.append(suppl_row.name)\n",
    "                suppl_row.write(suppl_unmatched_file)\n",
    "                suppl_unmatched += 1\n",
    "                suppl_row = Row(suppl_sorted_file)\n",
    "                inc_suppl()\n",
    "\n",
    "        matching_name = npi_row.name # = suppl_row.name\n",
    "        #print('matching name', matching_name)\n",
    "        npi_rows = [npi_row]\n",
    "        suppl_rows = [suppl_row]\n",
    "        while True:\n",
    "            npi_row = Row(npi_sorted_file)\n",
    "            inc_npi()\n",
    "            if npi_row.name == matching_name:\n",
    "                npi_rows.append(npi_row)\n",
    "            else:\n",
    "                break\n",
    "        while True:\n",
    "            suppl_row = Row(suppl_sorted_file)\n",
    "            inc_suppl()\n",
    "            if suppl_row.name == matching_name:\n",
    "                suppl_rows.append(suppl_row)\n",
    "            else:\n",
    "                break\n",
    "        #print('npi_rows', npi_rows)\n",
    "        #print('suppl_rows', suppl_rows)\n",
    "\n",
    "        matches = match_rows(npi_rows, suppl_rows)\n",
    "        #print('debug', debug)\n",
    "        bad_skips = set(npi_skipped).intersection(suppl_skipped)\n",
    "        if len(bad_skips) > 0 or debug:\n",
    "            if len(npi_skipped) > 0:\n",
    "                print('npi skipped:', npi_skipped)\n",
    "            if len(suppl_skipped) > 0:\n",
    "                print('suppl skipped:', suppl_skipped)\n",
    "\n",
    "            #if len(npi_skipped) > 10 or len(suppl_skipped) > 10:\n",
    "            print('matches %-30s: %d matched, npi: %2d/%2d, suppl: %2d/%2d' % (matching_name,\n",
    "                                                                           len(matches),\n",
    "                                                                           len(npi_rows),\n",
    "                                                                           len(npi_rows) + len(npi_skipped),\n",
    "                                                                           len(suppl_rows),\n",
    "                                                                           len(suppl_rows) + len(suppl_skipped)))\n",
    "        if len(bad_skips) > 0:\n",
    "            print('BAD SKIPS', len(bad_skips), bad_skips)\n",
    "            print('npi', npi_skipped)\n",
    "            print('suppl', suppl_skipped)\n",
    "            break\n",
    "\n",
    "        for match in matches:\n",
    "            matched += 1\n",
    "            write_match(matches_file, match)\n",
    "        #print(matches)\n",
    "except EOFError as e:\n",
    "    print('End of input')\n",
    "\n",
    "npi_unmatched_file.close()\n",
    "suppl_unmatched_file.close()\n",
    "matches_file.close()\n",
    "npi_sorted_file.close()\n",
    "suppl_sorted_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db221bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
